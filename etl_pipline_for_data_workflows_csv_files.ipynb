{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785f2439",
   "metadata": {},
   "source": [
    "# Developing Robust ETL Pipelines for Data Science Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504aaed",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "Extract data from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd43a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to extract data from a CSV file\n",
    "def extract_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data extracted from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract employee data\n",
    "employee_data = extract_data('/content/employees_data.csv')\n",
    "\n",
    "# Print the first few rows of the data\n",
    "if employee_data is not None:\n",
    "    print(employee_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce6551",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "- Handling Missing Data: Remove or fill in missing values.\n",
    "- Creating Derived Features: Make new columns, like salary bands or age groups.\n",
    "- Encoding Categories: Change data like department names into a format computers can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform employee data \n",
    "def transform_data(data):\n",
    "    try:\n",
    "        \n",
    "        # Ensure salary and age are numeric and handle any errors\n",
    "        data['Salary'] = pd.to_numeric(data['Salary'], errors='coerce')\n",
    "        data['Age'] = pd.to_numeric(data['Age'], errors='coerce')\n",
    "\n",
    "        # Remove rows with missing values\n",
    "        data = data.dropna(subset=['Salary', 'Age', 'Department'])\n",
    "\n",
    "        # Create salary bands\n",
    "        data['Salary_band'] = pd.cut(data['Salary'], bins=[0, 60000, 90000, 120000, 1500000], labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "        # Create age groups\n",
    "        data['Age_group'] = pd.cut(data['Age'], bins=[0, 30, 40, 50, 60], labels=['Young', 'Middle-aged', 'Senior', 'Older'])\n",
    "\n",
    "        # Convert department to categorical\n",
    "        data['Department'] = data['Department'].astype('category')\n",
    "\n",
    "        print(\"Data transformation complete\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error in transformation: {e}\")\n",
    "        return None\n",
    "\n",
    "employee_data = extract_employee_data('/content/employees_data.csv')\n",
    "\n",
    "# Transform the employee data\n",
    "if employee_data is not None:\n",
    "    transformed_employee_data = transform_data(employee_data)\n",
    "\n",
    "    # Print the first few rows of the transformed data\n",
    "    print(transformed_employee_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22453080",
   "metadata": {},
   "source": [
    "## Data Storage\n",
    "Load data into a database. This makes it easy to search and analyze.\n",
    "Here is SQLite DB used. It is a lightweight database that stores data. Create a table called employees in the SQLite database, then insert the transformed data into this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efab42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Function to load transformed data into SQLite database\n",
    "def load_data_to_db(data, db_name='employee_data.db'):\n",
    "    try:\n",
    "        # Connect to SQLite database (or create it if it doesn't exist)\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create table if it doesn't exist\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS employees (\n",
    "                employee_id INTEGER PRIMARY KEY,\n",
    "                first_name TEXT,\n",
    "                last_name TEXT,\n",
    "                salary REAL,\n",
    "                age INTEGER,\n",
    "                department TEXT,\n",
    "                salary_band TEXT,\n",
    "                age_group TEXT\n",
    "            )\n",
    "        ''')\n",
    "\n",
    "        # Insert data into the employees table\n",
    "        data.to_sql('employees', conn, if_exists='replace', index=False)\n",
    "\n",
    "        # Commit and close the connection\n",
    "        conn.commit()\n",
    "        print(f\"Data loaded into {db_name} successfully\")\n",
    "\n",
    "        # Query the data to verify it was loaded\n",
    "        query = \"SELECT * FROM employees\"\n",
    "        result = pd.read_sql(query, conn)\n",
    "        print(\"\\nData loaded into the database:\")\n",
    "        print(result.head())  # Print the first few rows of the data from the database\n",
    "\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in loading data: {e}\")\n",
    "\n",
    "load_data_to_db(transformed_employee_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22b423",
   "metadata": {},
   "source": [
    "## Running the Complete ETL Pipeline\n",
    "The pipeline will get the employee data. It will clean and change the data. Finally, it will save the data in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20471456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_etl_pipeline(file_path, db_name='employee_data.db'):\n",
    "    # Extract\n",
    "    data = extract_employee_data(file_path)\n",
    "    if data is not None:\n",
    "        # Transform\n",
    "        transformed_data = transform_employee_data(data)\n",
    "        if transformed_data is not None:\n",
    "            # Load\n",
    "            load_data_to_db(transformed_data, db_name)\n",
    "\n",
    "# Run the ETL pipeline\n",
    "run_etl_pipeline('/content/employees_data.csv', 'employee_data.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
